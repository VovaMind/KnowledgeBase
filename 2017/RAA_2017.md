#  RAA 2017

##### Содержание
[Longest path algorithms](#longestpath)  
[Graph algorithms and continious optimization](#graph)  
[Streaming algorithms](#stream)  
[Multi dimensional algorithms](#multidim)  

<a name="longestpath"/>

# Longest path algorithms
Поиск вершинного покрытия, Гамильтового пути или пути длины k. 

Все это нормально не решается, но можно получить лучшие оценки.

Можно наивно, но можно еще лучше. Для лучших оценок используется определенный набор техник.

Техники: colored coding, divide and color, narrow sieves, representative families.

Есть рандомизированные алгоритмы, есть точные. Все экспоненциальные.

Рассмотрение все подмножеств и переходов между ними. Это все равно избыточно. 

Что-то про подбор цветов и случайные раскраски, если мы угадаем с цветами и порядком, то все полиномиально. И есть способы получить улучшение из этого.

<a name="graph"/>

# Graph algorithms and continious optimization
Графы полезные, много алгоритмов, но они комбинаторные. Их сложно придумывать, сложно анализировать, нужна экспертиза.

Поток полезный используется в сегментации (computer vision).

Можно использовать непрерыную оптимизацию. 

Рассматриваем неориетированный вариант (c=1). Рассматриваем поток как вектор (обратные потоки отрицательные). 

Минимизируем l-норму вектора (minmax), рассматриваем пространство потоков величины 1. Это ровно maxflow, только нужно масштабировать.

subgradient descent, идем в направлении градиента, делаем проекцию в пространство потоков величины 1. Проекция - это переходим к задаче electrical flow.

Laplassian, собственные числа. Второе число 0 для несвязного графа, cut conductamce, graph conductance, sparsity.

Второе число большое для сильно связных графов, маленькое для разреженных.

История про итеративную оптимизацию, последовательность точек, разложение тэйлора и из этого получаем градиентый спуск, можно рассматривать до второй производной.

Хорошо работает для выпуклой функции, используем softmax вместо l-нормы (?).

Там дальше куча приближенок на разных этапах + вспомогательная математика для этого всего.

<a name="stream"/>

# Streaming algorithms
Обработка больших данных с использованием небольшого количества памяти.

Большой поток данных, поддерживаем статистику.

Один проход (или несколько), число элементов известно, сублинейная память, быстро обрабатываем элемент.

Рандомизированные алгоритмы, различные элементы, порядковые статистики.

Поиск числа различных элементов, пример задачи с роутером, запросы в гугл, можно хэш но это O(N) памяти.

Вероятностный алгоритм, оценка для вероятности.

Есть ли t разных элементов. Случайное подмножество элементов и считаем их количество. И там проверяем 0 или нет (?).

alon matias szeregedy 96

CountSketch алгоритм

Выдать k самых частых элементов из последовательности из N.

FindTop структура данных для поиска k самых частых элементов, PointQuery - сколько конкретного элемента.

Для k=1 решается так: случайно для каждого элемента мапинг в -1 / +1. Ответ сумма по элементам умножить на знак. В среднем получаем частоту самого частого элемента, не работает для равномерного.

Hash в несколько корзин O(K), простая оценка для каждого оценщика. Повторяем O(logN) раз и берем медиану.

По сути мы находим самый частый элемент и фильтруем шум.

Стрим графа. Поддерживаем spanning tree, удаляем и добавляем ребра.

Матрица - число ребер на число вершин и случайные +1 -1 на ребра. Эту матрицу можно использовать.

Single pass algorithm, unpack spectral singapore fast, k lee musco sidford 2014

heavy hitters CountSketch, AMA sketch

<a name="multidim"/>

# Multi dimensional algorithms
Геометрические алгоритмы, большие данные (типа мешко слов), посик близких точек и кластеров. Curse of dimensionality (все сильно хуже с размером пространства).

https://falconn-lib.org/

Рандомизированные алгоритмы. Распределение точек в sqrt(n) полосе для сферы и так далее. 

Никогда не реализуй свою собственную линейную алгебру. Используй openblas, eigen. Работает раз в 4-5 быстрее.

ailon, chazelle 2006 fast random projection

Равномерное подмножество координат, можем потерять информацию. Но общий смысл в переходе пространство меньшей размерности.

Плотный случай - это плохо.

Применяем случайный поворт для данных с помощью ортогональной матрицы, но напрямую это делать сложно. Нужен оптимальный план для этого.

Не обязательно делать совсем случайно, fast Hadamard  transformation

Это сохраняет расстояния. Можно сделать за O(DlogD) с помощью разделяй и властвуй

Перед траснформацией придумываем случайные знаки для размерностей.

Не пиши свое FFT, используй библиотеку FFTW. Есть реализация в R. Реализация есть тут https://github.com/Falconn-lib/ffht

Нужно останаливать рекурсию на каком-то уровне. Константы важны, это все работает быстрее в 10 раз чем сортировка.

PCA хорошо для sharp dimension случая. Получаем направления с самой большой varience для проекций.

Поиск ближайших точек: находить ближайшие точки из набора для запросов из точек.

Нужно что-то вроде многомерной диаграмы Вороного.

Используем local sensitive hashing.

Indyk motwani 1998

Есть результаты из 2017.

10kk точек в бинарном пространстве размера 1024, ближайшие соседи имеют расстояние порядка 150. Берем k случайных координат и проверяем только те точки, у которых они совпадают. Можно использовать неколько таких наборов.

Для поиска ближайшего предка из набора нужно просматривать корзины разбитые по 23-м координатам. Повторяем для 40 наборов.

Общий принцип такого разбиения на корзины - O(1) точек в одной корзине.

Можно перейти от N-мерного пространства к сфере.

simhash charikar 2002

Придумываем случайный вектор, находи подмножества с заметно положительной корреляцией. Можно это делать рекурсивно вглубь. По сути обобщение бинарной идеи но в многомерном пространстве.

Extract dense clusters before partition(?). 

locality sensitive hashing, hyperplane LSH, simhash

Charikar 2002

Voronoi LSH, optimal LSH family

Structuder randomness is better, than pure

Teresa Tanaka 2007

Случайный поворот непрактичен, нужен псевдо-случайный

ailon chazelle 2006 handamard transform

Несколько итераций: случайно выбрали знаки и сделали трансформацию (2-3 итерации), O(DlogD) сложность, память можно улучшать.

Multiprobe LSH

Hashing trick for sparse multidimensional data (like bag of words) - CountSketch

compressed index
